{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b655f09b-7c91-4b6d-ac13-7203a360903e",
   "metadata": {},
   "source": [
    "# day04 Advanced fine-tuning and customization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b2f6a9-de86-45d8-8a4b-1365d830bd39",
   "metadata": {},
   "source": [
    "* sst2 dataset\n",
    "* train and tests dataset\n",
    "* ver interesting table: sentence - tokens - ids - n_tokens - essential_tokens\n",
    "* predicting labels from other datasets different fron sst2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e464377d-8975-4cb3-97c1-d9569eae5b26",
   "metadata": {},
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3afc5b-e646-40ff-b30c-54a0c39aefa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]<=2024.6.1,>=2023.1.0\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.32.2\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.66.3\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 KB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/dgerwig-/.local/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 KB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 KB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/dgerwig-/.local/lib/python3.10/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pandas in /home/dgerwig-/.local/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.21.2\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 KB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 KB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 KB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dgerwig-/.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (3.3)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (1.26.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dgerwig-/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/dgerwig-/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/dgerwig-/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, tqdm, pyarrow, multidict, fsspec, frozenlist, filelock, dill, charset-normalizer, async-timeout, aiohappyeyeballs, yarl, requests, multiprocess, aiosignal, huggingface-hub, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 async-timeout-4.0.3 charset-normalizer-3.3.2 datasets-2.21.0 dill-0.3.8 filelock-3.15.4 frozenlist-1.4.1 fsspec-2024.6.1 huggingface-hub-0.24.6 multidict-6.0.5 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 tqdm-4.66.5 xxhash-3.5.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f7499d-3083-449f-b4b2-54fa9e3d29d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/dgerwig-/.local/lib/python3.10/site-packages (from transformers) (0.24.6)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/dgerwig-/.local/lib/python3.10/site-packages (from transformers) (3.15.4)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/dgerwig-/.local/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: requests in /home/dgerwig-/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.5/435.5 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/dgerwig-/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dgerwig-/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dgerwig-/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Installing collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.7.24 safetensors-0.4.4 tokenizers-0.19.1 transformers-4.44.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d50ef8d-ff32-498b-aa1e-ecd33b175d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multiprocess in /home/dgerwig-/.local/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: packaging in /home/dgerwig-/.local/lib/python3.10/site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from evaluate) (2024.6.1)\n",
      "Requirement already satisfied: xxhash in /home/dgerwig-/.local/lib/python3.10/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from evaluate) (0.24.6)\n",
      "Requirement already satisfied: dill in /home/dgerwig-/.local/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/dgerwig-/.local/lib/python3.10/site-packages (from evaluate) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/dgerwig-/.local/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: pandas in /home/dgerwig-/.local/lib/python3.10/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from evaluate) (2.21.0)\n",
      "Requirement already satisfied: aiohttp in /home/dgerwig-/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: filelock in /home/dgerwig-/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dgerwig-/.local/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dgerwig-/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2020.6.20)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/dgerwig-/.local/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dgerwig-/.local/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/dgerwig-/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/dgerwig-/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/dgerwig-/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/dgerwig-/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a99bb16-d3fd-485a-8d32-2c26404ad999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a186658-0df4-449e-99c7-f1ddf5e0cae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Requirement already satisfied: scikit-learn in /home/dgerwig-/.local/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/dgerwig-/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/lib/python3/dist-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c567e9d-d382-4d3f-9f74-99ae0600048c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Requirement already satisfied: seaborn in /home/dgerwig-/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/dgerwig-/.local/lib/python3.10/site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/dgerwig-/.local/lib/python3.10/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/dgerwig-/.local/lib/python3.10/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/dgerwig-/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/dgerwig-/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.29.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dgerwig-/.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.2->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/dgerwig-/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "612fc481-2de6-439b-9e89-f7764754eb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /home/dgerwig-/.local/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in /home/dgerwig-/.local/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from accelerate) (0.24.6)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/dgerwig-/.local/lib/python3.10/site-packages (from accelerate) (0.4.4)\n",
      "Collecting torch>=1.10.0\n",
      "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m504.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dgerwig-/.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/dgerwig-/.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: filelock in /home/dgerwig-/.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/dgerwig-/.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in /home/dgerwig-/.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.0.0\n",
      "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 KB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.10.0->accelerate) (3.0.3)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /home/dgerwig-/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch>=1.10.0->accelerate) (1.9)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dgerwig-/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, accelerate\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f356f062-ed4b-4260-ae96-6967f82ab1b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was a problem when trying to write in your cache folder (/home/dgerwig-/.cache/huggingface/hub). You should set the environment variable TRANSFORMERS_CACHE to a writable directory.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer, TrainingArguments\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mevaluate\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import evaluate\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bda474-c51f-418e-aa20-0957f2d8be71",
   "metadata": {
    "tags": []
   },
   "source": [
    "# importing the model - tokenizer - dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04084c-b880-44f0-ad0c-1fcf19b353ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'num_labels=2' specifies that this is a binary classification task.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2)\n",
    "# DistilBERT is a smaller, faster version of BERT. It has already been \n",
    "# pre-trained on general language tasks, and we are now fine-tuning it \n",
    "# on the SST-2 dataset for sentiment classification (positive vs negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0dd2fd-cfc3-4195-a010-a60bb6eeac23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the tokenizer for DistilBERT (or any other model to fine-tune).\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e4c076-449b-4991-a82b-4ee948bd127a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the SST-2 dataset from the GLUE benchmark.\n",
    "# The 'sst2' configuration is used for sentiment classification tasks.\n",
    "dataset = load_dataset('glue', 'sst2')\n",
    "\n",
    "# The SST-2 dataset is a binary classification dataset for sentiment \n",
    "# analysis. It contains sentences with labels 0 (negative) and 1 (positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6223ae-f687-4a28-8d7b-896143d5bae8",
   "metadata": {},
   "source": [
    "## predicting with the pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b37cce-4f7e-46ad-9d4c-301b43e00d87",
   "metadata": {},
   "source": [
    "### predicting a single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8819d80b-acab-49af-93de-03e60ffab663",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentiment_predict(sentence):\n",
    "    \"\"\"\n",
    "    Takes a sentence and returns the original sentence, the tokenized sentence,\n",
    "    the token IDs, the softmax probabilities, and the predicted label.\n",
    "\n",
    "    Args:\n",
    "    - sentence (str): The input sentence for sentiment analysis.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary containing:\n",
    "        - 'original_sentence': The original sentence.\n",
    "        - 'tokenized_sentence': The tokenized version of the sentence.\n",
    "        - 'input_ids': The token IDs (numerical representation).\n",
    "        - 'softmax_probs': The softmax probabilities for each class.\n",
    "        - 'predicted_label': The predicted class label.\n",
    "        - 'sentiment': Sentiment as 'positive' or 'negative'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Tokenize the sentence\n",
    "    tokens = tokenizer(sentence, return_tensors=\"pt\", padding=\"longest\", truncation=True, max_length=512)\n",
    "    \n",
    "    # Step 2: Get the token IDs and tokenized sentence\n",
    "    input_ids = tokens['input_ids']\n",
    "    tokenized_sentence = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    \n",
    "    # Step 3: Pass the tokenized input to the model to get logits\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        output = model(**tokens)\n",
    "        logits = output.logits\n",
    "    \n",
    "    # Step 4: Apply softmax using torch to get probabilities\n",
    "    softmax_probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Step 5: Get the predicted label (argmax of softmax output)\n",
    "    predicted_label = torch.argmax(softmax_probs, dim=-1).item()\n",
    "    \n",
    "    # Step 6: Determine sentiment based on the predicted label\n",
    "    sentiment_label = \"positive\" if predicted_label == 1 else \"negative\"\n",
    "    \n",
    "    # Step 7: Prepare result dictionary\n",
    "    result = {\n",
    "        \"original_sentence\": sentence,\n",
    "        \"tokenized_sentence\": tokenized_sentence,\n",
    "        \"input_ids\": input_ids[0].tolist(),\n",
    "        \"softmax_probs\": softmax_probs[0].tolist(),  # Convert tensor to list\n",
    "        \"predicted_label\": predicted_label,\n",
    "        \"sentiment\": sentiment_label\n",
    "    }\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183cf205-35cf-480c-8602-75a09a1fa490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence_label = sentiment_predict(\"I am happy as a angry bull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f7f32-5935-47f3-b660-da05144a8c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a94232-7568-4e2e-bea5-ef50bb27f1d9",
   "metadata": {},
   "source": [
    "### predicting a whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d420dd6-5abf-48ca-abb4-7cdfc731e726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def non_trained_new_data(n_new_samples):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a new subset of data and returns a DataFrame with\n",
    "    all the sentences, true labels, and predicted labels, along with accuracy\n",
    "    and a confusion matrix.\n",
    "\n",
    "    Args:\n",
    "    - n_new_samples: Number of new samples to use from the original test set.\n",
    "    - model: The pre-trained or fine-tuned model to use for predictions.\n",
    "    - tokenizer: The tokenizer associated with the model.\n",
    "    - dataset: The dataset containing 'sentence' and 'label' fields.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame of sentences, true labels, and predicted labels.\n",
    "    - Accuracy on the new dataset.\n",
    "    - Confusion matrix (formatted).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Create a subset of new data from the original test dataset\n",
    "    new_data = dataset['validation'].shuffle(seed=12).select(range(n_new_samples))\n",
    "\n",
    "\n",
    "    # Step 2: Tokenize the new test dataset\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples['sentence'], padding=\"longest\", truncation=True, max_length=512)\n",
    "    \n",
    "    tokenized_new_data = new_data.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Step 3: Remove the 'sentence' column after tokenization, set format to PyTorch tensors\n",
    "    tokenized_new_data = tokenized_new_data.remove_columns([\"sentence\"])\n",
    "    tokenized_new_data.set_format(\"torch\")\n",
    "\n",
    "    # Step 4: Prepare inputs for the model\n",
    "    input_ids = tokenized_new_data['input_ids'].clone().detach()\n",
    "    attention_mask = tokenized_new_data['attention_mask'].clone().detach()\n",
    "\n",
    "    # Prepare inputs as dictionary\n",
    "    inputs = {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask\n",
    "    }\n",
    "\n",
    "    # Step 5: Run predictions using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get predicted labels\n",
    "    predicted_labels = torch.argmax(logits, dim=-1).numpy()\n",
    "\n",
    "    # True labels from the dataset\n",
    "    true_labels = tokenized_new_data['label']\n",
    "\n",
    "    # Extract the actual sentences for display\n",
    "    sentences = new_data[\"sentence\"]\n",
    "\n",
    "    # Step 6: Calculate Accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Step 7: Create Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Step 8: Format the data in a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Sentence\": sentences,\n",
    "        \"True Label\": true_labels,\n",
    "        \"Predicted Label\": predicted_labels\n",
    "    })\n",
    "\n",
    "    # Return the DataFrame, accuracy, and confusion matrix\n",
    "    return df, accuracy, conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430c383a-af7b-4b51-b354-40a782a99683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_non_trained, accuracy_non_trained, conf_matrix_non_trained= non_trained_new_data(n_new_samples = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0eb424-3efc-4ff3-a01e-621d05290b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_non_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a328f1a-faf2-4b23-8af0-343f4a6663d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_non_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4e6168-572e-49f6-bb46-624537eb91fd",
   "metadata": {},
   "source": [
    "## selecting and tokenizing train - test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f1148a-90f1-45cd-be09-76c2deb1aece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sampling a smaller subset for training and testing.testing to keep \n",
    "# things lightweight\n",
    "n_train = 600   # Number of training samples\n",
    "n_test = 150    # Number of testing samples\n",
    "\n",
    "# Shuffle the training and test datasets and select a subset.\n",
    "train_dataset = dataset['train'].shuffle(seed=42).select(range(n_train))\n",
    "test_dataset = dataset['validation'].shuffle(seed=42).select(range(n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f3946-0401-4371-8bc2-4656184d9c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to tokenize the sentences in the dataset.\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['sentence'],           # The text field in SST-2 is 'sentence'\n",
    "        padding=\"longest\",              # Pad to a fixed length (512 tokens)\n",
    "        truncation=True,                # Truncate if the sentence is longer\n",
    "        max_length=512                  # Max token length\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4c791-b94b-41b7-8b07-5a5b909118d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize the training dataset\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Tokenize the test dataset\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Explanation:\n",
    "# The tokenizer converts the sentences into token IDs that the \n",
    "# model can process. We use padding and truncation to ensure all \n",
    "# inputs are 512 tokens long. The function 'map' applies the \n",
    "# tokenization to all examples in the dataset in batches for speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324b8225-fca5-45d1-a920-f53d34df4820",
   "metadata": {},
   "source": [
    "## sentence - number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e7e48-34f5-4dac-94b9-dbc46fff7b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the special token ID for padding, usually tokenizer.pad_token_id\n",
    "pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0b133-bbec-4d74-b8dc-35259640359c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to process the tokenized dataset and extract necessary fields\n",
    "def extract_token_info_with_essential_tokens(example):\n",
    "    # Get the original sentence\n",
    "    original_sentence = example['sentence'] if 'sentence' in example else None\n",
    "    \n",
    "    # Get the tokenized sentence by converting token IDs back to tokens\n",
    "    tokenized_sentence = tokenizer.convert_ids_to_tokens(example['input_ids'])\n",
    "    \n",
    "    # Count the number of tokens excluding padding\n",
    "    essential_tokens = sum(1 for token_id in example['input_ids'] if token_id != pad_token_id)\n",
    "    \n",
    "    # Return original sentence, tokenized sentence, token IDs, total tokens, and essential tokens\n",
    "    return {\n",
    "        'sentence': original_sentence,  # The original sentence\n",
    "        'tokenized_sentence': \" \".join(tokenized_sentence),  # Tokenized sentence as a string\n",
    "        'token_ids': example['input_ids'],  # List of token IDs\n",
    "        'num_tokens': len(example['input_ids']),  # Total number of tokens (including padding)\n",
    "        'essential_tokens': essential_tokens  # Number of tokens excluding padding\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890ae91-c799-430a-956b-977b1de19244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the extraction function to the already tokenized dataset\n",
    "processed_train = tokenized_train.map(extract_token_info_with_essential_tokens, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af9886-228f-4df3-a997-5d5ad330004b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame from the processed dataset\n",
    "train_data = [\n",
    "    {\n",
    "        \"sentence\": ex['sentence'], \n",
    "        \"tokenized_sentence\": ex['tokenized_sentence'],  # Tokenized sentence as a string\n",
    "        \"token_ids\": ex['token_ids'], \n",
    "        \"num_tokens\": ex['num_tokens'],  # Total tokens (with padding)\n",
    "        \"essential_tokens\": ex['essential_tokens']  # Number of tokens without padding\n",
    "    }\n",
    "    for ex in processed_train\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4464170-e537-430b-a3ec-b127b50a2b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame\n",
    "df_train = pd.DataFrame(train_data)\n",
    "\n",
    "# Sort the DataFrame by the number of essential tokens in descending order\n",
    "df_train = df_train.sort_values(by=\"essential_tokens\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb2cab-23ac-4250-b2a4-9c861e56e23b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e50d387-fa63-4260-af7e-3a705f2546ec",
   "metadata": {},
   "source": [
    "## prepare datasets for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214926c-9aec-4347-8eba-ab678498f8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the 'sentence' and 'idx' columns from the tokenized_train dataset\n",
    "tokenized_train = tokenized_train.remove_columns([\"sentence\", \"idx\"])\n",
    "\n",
    "# Remove the 'sentence' and 'idx' columns from the tokenized_test dataset\n",
    "tokenized_test = tokenized_test.remove_columns([\"sentence\", \"idx\"])\n",
    "\n",
    "# Check the columns after removal (optional, for confirmation)\n",
    "print(tokenized_train.column_names)\n",
    "print(tokenized_test.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25878e34-238b-4347-abce-6903d84887d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hugging Face's Trainer API expects the data in PyTorch format.\n",
    "tokenized_train.set_format(\"torch\")\n",
    "tokenized_test.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f7081-f982-41b6-ac63-7db027c5b784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733e8ffa-902a-431b-a35e-25c96aad5923",
   "metadata": {},
   "source": [
    "# Finetuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a8ad4-fe2d-4ced-809b-9baa46f5542c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd56f01-cf4a-4716-a992-051aa52e93ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb2a00-44a0-41e1-be14-0a9add0b229a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc46a7-b9f3-496f-8c1d-7c6700e68edd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Detailed Explanation of `DistilBertConfig`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd8331-9a0f-4d49-b453-eb0d2bf23c53",
   "metadata": {},
   "source": [
    "\n",
    "This configuration describes the architecture and hyperparameters for the `DistilBERT` model. Below is an in-depth explanation of each field in the configuration:\n",
    "\n",
    "1. **`_name_or_path`: \"distilbert-base-uncased\"`  \n",
    "   - This specifies the name or path of the pretrained model. \n",
    "   - `\"distilbert-base-uncased\"` is a smaller, lighter version of BERT that removes the case sensitivity of text (i.e., it treats \"Hello\" and \"hello\" the same way).\n",
    "   \n",
    "2. **`activation`: \"gelu\"`  \n",
    "   - This defines the activation function used in the model.  \n",
    "   - `\"gelu\"` stands for **Gaussian Error Linear Unit**, which is a smoother version of ReLU and commonly used in transformer models.\n",
    "\n",
    "3. **`architectures`: [\"DistilBertForMaskedLM\"]**  \n",
    "   - This indicates the type of architecture being used.  \n",
    "   - `DistilBertForMaskedLM` is the architecture for **Masked Language Modeling**, where the model predicts missing or masked words in sentences. This is used for pretraining BERT-based models.\n",
    "\n",
    "4. **`attention_dropout`: 0.1**  \n",
    "   - Dropout rate for the attention layers.  \n",
    "   - Dropout is a regularization technique used to prevent overfitting by randomly setting a fraction of the attention scores to zero during training. In this case, the rate is 10% (0.1).\n",
    "\n",
    "5. **`dim`: 768**  \n",
    "   - The dimensionality of the hidden representations in the model.  \n",
    "   - Each input token is represented by a vector of size 768 in this version of DistilBERT.\n",
    "\n",
    "6. **`dropout`: 0.1**  \n",
    "   - The general dropout rate applied throughout the model.  \n",
    "   - This helps prevent overfitting by randomly dropping 10% of the neurons during training.\n",
    "\n",
    "7. **`hidden_dim`: 3072**  \n",
    "   - This represents the size of the hidden layer in the feedforward neural network part of the transformer model.  \n",
    "   - Specifically, this is the size of the intermediate layer in each transformer block, which typically has a larger dimension (3072) compared to the input/output dimension (768).\n",
    "8. **`initializer_range`: 0.02**  \n",
    "   - This defines the range used to initialize the weights in the model.  \n",
    "   - The model’s weights are initialized using a uniform distribution in the range [-0.02, 0.02].\n",
    "\n",
    "9. **`max_position_embeddings`: 512**  \n",
    "   - The maximum number of tokens or positions that the model can handle.  \n",
    "   - For DistilBERT, this is capped at 512 tokens. Any input longer than 512 tokens will be truncated.\n",
    "\n",
    "10. **`model_type`: \"distilbert\"`  \n",
    "   - This defines the type of model being used.  \n",
    "   - `distilbert` is a distilled version of the BERT model, which retains 97% of BERT’s performance but is 60% faster and smaller in size.\n",
    "\n",
    "11. **`n_heads`: 12**  \n",
    "   - The number of attention heads in the multi-head attention mechanism.  \n",
    "   - In transformer architectures like BERT, the attention mechanism is split into multiple \"heads\" that focus on different parts of the input sequence. DistilBERT uses 12 attention heads.\n",
    "\n",
    "12. **`n_layers`: 6**  \n",
    "   - The number of layers (transformer blocks) in the model.  \n",
    "   - DistilBERT has 6 layers, as opposed to the 12 layers in BERT. This reduction is one reason why DistilBERT is faster and smaller.\n",
    "\n",
    "13. **`pad_token_id`: 0**  \n",
    "   - The token ID used to represent padding in the input sequence.  \n",
    "   - Padding tokens are added to make all sequences in a batch the same length, and `0` is the ID for the padding token.\n",
    "\n",
    "14. **`qa_dropout`: 0.1**  \n",
    "   - Dropout rate applied during the Question Answering (QA) head of the model.  \n",
    "   - This is used in tasks like SQuAD (Stanford Question Answering Dataset), where a 10% dropout rate is applied.\n",
    "\n",
    "15. **`seq_classif_dropout`: 0.2**  \n",
    "   - Dropout rate used in the sequence classification head of the model.  \n",
    "   - This is applicable for tasks like text classification, where a 20% dropout rate is applied to prevent overfitting.\n",
    "\n",
    "16. **`sinusoidal_pos_embds`: false**  \n",
    "   - This flag indicates whether sinusoidal positional embeddings are used.  \n",
    "   - DistilBERT uses learned positional embeddings (as in the original BERT) instead of sinusoidal ones.\n",
    "\n",
    "17. **`tie_weights_`: true**  \n",
    "   - This indicates whether the weights of the embeddings and the output layer are tied.  \n",
    "   - Weight tying reduces the number of parameters in the model and ensures that the input and output embeddings are similar.\n",
    "\n",
    "18. **`transformers_version`: \"4.44.0\"**  \n",
    "   - This specifies the version of the Hugging Face Transformers library used to configure the model.  \n",
    "   - In this case, the version is 4.44.0.\n",
    "\n",
    "19. **`vocab_size`: 30522**  \n",
    "   - The size of the vocabulary used by the tokenizer and the model.  \n",
    "   - DistilBERT inherits the BERT tokenizer, which uses a vocabulary of 30,522 tokens. This includes words, subwords, and special tokens (like [PAD], [CLS], etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9bbb9e-d86d-4799-86eb-a3bb2e95627d",
   "metadata": {},
   "source": [
    "## training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2679d-08aa-4fab-b845-e777b3b8a632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load accuracy as the evaluation metric. This will be used to compute\n",
    "# the accuracy of the model on the validation dataset during evaluation.\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Define the function to compute metrics (accuracy in this case).\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d256a14-d35d-4d11-b102-fa3fe76b6732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the training arguments, which control how the model will be trained.\n",
    "# Each argument has a direct or indirect impact on both the computation time \n",
    "# and the model's final performance.\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          # Directory where the model's checkpoints \n",
    "                                     # and outputs will be saved. \n",
    "                                     # (Doesn't directly affect training time)\n",
    "\n",
    "    eval_steps=5,                    # Evaluate the model every  eval_steps. \n",
    "                                     # Frequent evaluations can slow down training, \n",
    "                                     # but provide insights into model performance \n",
    "                                     # during training. Adjust this number based on \n",
    "                                     # the size of your dataset and training speed.\n",
    "\n",
    "    learning_rate=2e-5,              # Learning rate controls the speed at which \n",
    "                                     # the model updates weights during training. \n",
    "                                     # A higher rate may lead to faster convergence, \n",
    "                                     # but could also risk overshooting optima, \n",
    "                                     # while a lower rate results in slower but \n",
    "                                     # potentially more stable training.\n",
    "\n",
    "    per_device_train_batch_size=16,  # Batch size for training on each device (GPU/CPU).\n",
    "                                     # A larger batch size speeds up training by \n",
    "                                     # processing more data per step, but uses more memory. \n",
    "                                     # If you run out of memory, reduce this value. \n",
    "                                     # Smaller batch sizes mean more updates per epoch.\n",
    "\n",
    "    per_device_eval_batch_size=64,   # Batch size for evaluation (validation/test set).\n",
    "                                     # Larger batch sizes can make evaluation faster \n",
    "                                     # but require more memory. Evaluation only happens \n",
    "                                     # during the validation phase, so it doesn't affect \n",
    "                                     # the training speed.\n",
    "\n",
    "    num_train_epochs=5,              # Number of training epochs. Each epoch is one full \n",
    "                                     # pass through the training dataset. More epochs \n",
    "                                     # increase training time but give the model more \n",
    "                                     # chances to learn. Fewer epochs result in faster \n",
    "                                     # training but risk underfitting the model.\n",
    "\n",
    "    gradient_accumulation_steps=3,   # Accumulate gradients over multiple steps before \n",
    "                                     # updating model weights. This simulates a larger \n",
    "                                     # batch size (e.g., with batch_size=16 and \n",
    "                                     # gradient_accumulation_steps=3, the model behaves \n",
    "                                     # like batch_size=48). This reduces memory usage \n",
    "                                     # but slows down training because updates happen \n",
    "                                     # less frequently.\n",
    "\n",
    "    weight_decay=0.01,               # Weight decay applies regularization during training \n",
    "                                     # to prevent overfitting by penalizing large weights. \n",
    "                                     # It improves generalization and helps ensure that \n",
    "                                     # the model performs well on unseen data.\n",
    "\n",
    "    logging_dir=\"./logs\",            # Directory for saving logs. Logging doesn't directly \n",
    "                                     # affect training speed, but frequent logging \n",
    "                                     # (e.g., at every step) can slow down the process. \n",
    "                                     # Set appropriate intervals for logging to balance \n",
    "                                     # information and speed.\n",
    "\n",
    "    logging_steps=100,               # Log metrics every 100 steps. Too frequent logging \n",
    "                                     # can slow training down, while infrequent logging \n",
    "                                     # might not provide enough insight into the model's \n",
    "                                     # performance during training. Adjust based on your \n",
    "                                     # need for monitoring.\n",
    "\n",
    "    save_strategy=\"epoch\",           # Save the model's checkpoints at the end of each \n",
    "                                     # epoch. This is generally efficient and safe \n",
    "                                     # unless you need more frequent saving (e.g., \"steps\").\n",
    "                                     # More frequent saving can slow down training, \n",
    "                                     # as saving checkpoints takes time.\n",
    "\n",
    "    load_best_model_at_end=True,     # Load the best model based on the evaluation \n",
    "                                     # metric after training finishes. While this \n",
    "                                     # doesn't affect training speed, it ensures the \n",
    "                                     # best-performing model (usually evaluated on \n",
    "                                     # validation accuracy or loss) is kept.\n",
    "\n",
    "    metric_for_best_model=\"accuracy\",# Monitor accuracy to select the best model.\n",
    "                                     # This defines the metric used to determine \n",
    "                                     # which model is considered the best when \n",
    "                                     # `load_best_model_at_end` is set to True.\n",
    "\n",
    "    evaluation_strategy=\"epoch\",     # Run evaluation at the end of each epoch. \n",
    "                                     # This balances training and evaluation time, \n",
    "                                     # allowing for regular checks on validation \n",
    "                                     # performance without frequent interruptions.\n",
    "\n",
    "    report_to=\"none\",                # No need to report results to external platforms \n",
    "                                     # like TensorBoard or Weights & Biases. This keeps \n",
    "                                     # overhead minimal and speeds up the training process \n",
    "                                     # if you're not interested in reporting metrics \n",
    "                                     # elsewhere.\n",
    "    \n",
    "    seed=42                          # Sets a fixed random seed to ensure reproducibility.\n",
    "                                     # Doesn't affect computation time but helps ensure \n",
    "                                     # the same results on re-runs.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6125ca4c-4b61-4225-9d45-da303f5fc0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                     # The model to fine-tune\n",
    "    args=training_args,              # Training arguments (from TrainingArguments)\n",
    "    train_dataset=tokenized_train,   # The tokenized training dataset\n",
    "    eval_dataset=tokenized_test,     # The tokenized evaluation dataset\n",
    "    compute_metrics=compute_metrics, # Function to compute evaluation metrics\n",
    "\n",
    "    # Additional Arguments\n",
    "    tokenizer=tokenizer,             # The tokenizer to use (optional, but useful if you \n",
    "                                     # want to use it for decoding or processing inputs).\n",
    "    \n",
    "    data_collator=None,              # A function to prepare batches of data. This is \n",
    "                                     # typically left as `None`, and the default \n",
    "                                     # collator is used, but you can define your own \n",
    "                                     # data collator if necessary (e.g., for dynamic \n",
    "                                     # padding).\n",
    "\n",
    "    optimizers=(None, None),         # You can provide your own optimizer and scheduler\n",
    "                                     # (learning rate scheduler). If `None`, the default \n",
    "                                     # AdamW optimizer and linear scheduler are used.\n",
    "\n",
    "    callbacks=None,                  # List of callbacks, such as `EarlyStoppingCallback`,\n",
    "                                     # to run during training. Callbacks can be used \n",
    "                                     # to perform additional actions during training.\n",
    "\n",
    "    preprocess_logits_for_metrics=None,  # If you want to pre-process logits before \n",
    "                                         # computing metrics, define a function here.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22028822-7885-42d8-9474-e20a6e26ce4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#trainer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c5804-3cf4-4d7d-990d-e2f0ce2eebd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 1 trainer.train()\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526bf3b2-a324-4a02-aa82-6726d3649ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run evaluation on both training and validation datasets\n",
    "train_eval_result = trainer.evaluate(eval_dataset=tokenized_train)  # Evaluate on training set\n",
    "#print(f\"Final training Accuracy: {train_eval_result['eval_accuracy']}\")\n",
    "\n",
    "test_eval_result = trainer.evaluate(eval_dataset=tokenized_test)    # Evaluate on test set\n",
    "#print(f\"Final test Accuracy: {test_eval_result['eval_accuracy']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d4b0d-6f2a-4de8-a13f-4fa7ffa740f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72714d56-c6c2-45dc-ab45-673ea1f88064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67142c7d-fda8-43a2-9f99-c988a49e5f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_eval_result['eval_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b522bd-0077-499a-9993-668fbb1d5df7",
   "metadata": {},
   "source": [
    "## questioning the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210f56d-569a-445f-a74e-f23f777603bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_label = sentiment_predict(\"I am happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b396d6-7161-4352-ad18-e4e379e9e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98fc388-e240-4e7e-bfd1-49ce5febbe3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07fde874-3668-4751-994c-b184b92e3ffb",
   "metadata": {},
   "source": [
    "## evaluating on new non seen sst2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3a642-da97-48d5-9cb9-a72a4b57f574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_on_new_data(n_new_samples):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a new subset of data and returns a DataFrame with\n",
    "    all the sentences, true labels, and predicted labels, along with accuracy\n",
    "    and a confusion matrix.\n",
    "\n",
    "    Args:\n",
    "    - n_new_samples: Number of new samples to use from the original test set.\n",
    "    \n",
    "    Returns:\n",
    "    - A DataFrame of sentences, true labels, and predicted labels.\n",
    "    - Accuracy on the new dataset.\n",
    "    - Confusion matrix (formatted).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Create a subset of new data from the original test dataset\n",
    "    new_data = dataset['validation'].shuffle(seed=12).select(range(n_new_samples))\n",
    "\n",
    "    # Step 2: Tokenize the new test dataset\n",
    "    # Tokenize the new test dataset with padding=\"longest\" to match the training data tokenization.\n",
    "    tokenized_new_data = new_data.map(lambda examples: tokenizer(\n",
    "    examples['sentence'], padding=\"longest\", truncation=True, max_length=512), batched=True)\n",
    "\n",
    "    # Remove the 'sentence' column after tokenization\n",
    "    tokenized_new_data = tokenized_new_data.remove_columns([\"sentence\"])\n",
    "\n",
    "    # Set the dataset format to PyTorch tensors\n",
    "    tokenized_new_data.set_format(\"torch\")\n",
    "\n",
    "    # Step 3: Evaluate the model on the new dataset and get predictions\n",
    "    predictions = trainer.predict(tokenized_new_data)\n",
    "    predicted_labels = predictions.predictions.argmax(axis=-1)\n",
    "\n",
    "    # predicted_labels = torch.argmax(torch.tensor(predictions.predictions), axis=1).numpy()\n",
    "    true_labels = predictions.label_ids\n",
    "\n",
    "    # Extract the actual sentences for display\n",
    "    sentences = new_data[\"sentence\"]\n",
    "\n",
    "    # Step 4: Accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Step 5: Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Step 6: Format the data in a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Sentence\": sentences,\n",
    "        \"True Label\": true_labels,\n",
    "        \"Predicted Label\": predicted_labels\n",
    "    })\n",
    "\n",
    "\n",
    "    # Return the DataFrame, accuracy, and confusion matrix\n",
    "    return df, accuracy, conf_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ed052-b3b7-4123-ac49-356258e1a8fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we cannot use the origianl funtion, as this function uses the trainer methods\n",
    "df, accuracy, conf_matrix = evaluate_on_new_data(n_new_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a697157-c715-4357-a742-8a537d37c3c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6cd33-6f30-46c3-b7f4-4a280e08da7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892ce3d6-df80-4415-bcf8-fe45e875655a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix):\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Pred Neg\", \"Pred Pos\"], yticklabels=[\"True Neg\", \"True Pos\"])\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951f027b-f4bc-46e7-bf49-21fbf1bc86cd",
   "metadata": {},
   "source": [
    "# compatible datsasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a3e5d1-3583-422d-b66e-16dd6b9f38a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_and_select_samples(dataset_name, n_samples):\n",
    "    \"\"\"\n",
    "    Downloads a dataset for sentiment analysis and selects a random subset of n_samples.\n",
    "    \n",
    "    Args:\n",
    "    - dataset_name: Name of the dataset (must be one of the compatible datasets).\n",
    "    - n_samples: Number of random samples to select.\n",
    "\n",
    "    Returns:\n",
    "    - new_data: A subset of the dataset with n_samples randomly selected.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Load the dataset\n",
    "    if dataset_name not in compatible_datasets:\n",
    "        raise ValueError(f\"Dataset '{dataset_name}' not found. Choose from {list(compatible_datasets.keys())}\")\n",
    "    \n",
    "    dataset_info = compatible_datasets[dataset_name]\n",
    "    \n",
    "    # Some datasets require specifying a subset\n",
    "    if isinstance(dataset_info, tuple):\n",
    "        dataset = load_dataset(*dataset_info)\n",
    "    else:\n",
    "        dataset = load_dataset(dataset_info)\n",
    "    \n",
    "    # Use the test split if available, otherwise use the train split\n",
    "    split = 'test' if 'test' in dataset else 'train'\n",
    "    data = dataset[split]\n",
    "    \n",
    "    # Step 2: Select a random sample of n_samples from the dataset\n",
    "    new_data = data.shuffle(seed=17).select(range(n_samples))\n",
    "    \n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289500ea-ea75-4320-95bf-1cdec2344446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_on_data(new_data, text_columns=[\"text\", \"sentence\", \"content\", \"title\"]):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a new subset of data and returns a DataFrame with\n",
    "    all the sentences, true labels, and predicted labels, along with accuracy\n",
    "    and a confusion matrix.\n",
    "\n",
    "    Args:\n",
    "    - new_data: The subset of the dataset to evaluate (already selected).\n",
    "    - trainer: Hugging Face Trainer object with the trained model.\n",
    "    - tokenizer: Tokenizer associated with the model.\n",
    "    - text_columns: A list of possible text columns to use (default: ['text', 'sentence', 'content', 'title']).\n",
    "    \n",
    "    Returns:\n",
    "    - df: DataFrame of sentences, true labels, and predicted labels.\n",
    "    - accuracy: Accuracy of the model on the new dataset.\n",
    "    - conf_matrix: Confusion matrix for the predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Find the appropriate text column\n",
    "    for col in text_columns:\n",
    "        if col in new_data.column_names:\n",
    "            text_column = col\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(f\"None of the specified text columns {text_columns} were found in the dataset.\")\n",
    "    \n",
    "    # Step 2: Tokenize the new dataset\n",
    "    tokenized_new_data = new_data.map(lambda examples: tokenizer(\n",
    "        examples[text_column], padding=\"longest\", truncation=True, max_length=512), batched=True)\n",
    "\n",
    "    # Remove the text column after tokenization\n",
    "    tokenized_new_data = tokenized_new_data.remove_columns([text_column])\n",
    "\n",
    "    # Set the dataset format to PyTorch tensors for model input\n",
    "    tokenized_new_data.set_format(\"torch\")\n",
    "\n",
    "    # Step 3: Evaluate the model on the new dataset and get predictions\n",
    "    predictions = trainer.predict(tokenized_new_data)\n",
    "    predicted_labels = predictions.predictions.argmax(axis=-1)\n",
    "    true_labels = predictions.label_ids\n",
    "\n",
    "    # Extract the actual sentences for display\n",
    "    sentences = new_data[text_column]\n",
    "\n",
    "    # Step 4: Compute Accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Step 5: Compute Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Step 6: Format the data in a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Sentence\": sentences,\n",
    "        \"True Label\": true_labels,\n",
    "        \"Predicted Label\": predicted_labels\n",
    "    })\n",
    "\n",
    "    # Return the DataFrame, accuracy, and confusion matrix\n",
    "    return df, accuracy, conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe0d2b-cb20-41ef-ac88-a1b268929ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the list of compatible datasets\n",
    "compatible_datasets = {\n",
    "    \"imdb\": \"imdb\",\n",
    "    \"yelp\": \"yelp_polarity\",\n",
    "    \"amazon\": \"amazon_polarity\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9da99e-ba90-43c7-8a45-4387afac1af6",
   "metadata": {},
   "source": [
    "### imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c10bba-99fa-453d-a131-3f709895418f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imdb_data = download_and_select_samples(dataset_name = \"imdb\", n_samples = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2c8fd-9e1c-4158-ab80-d1aa690e18cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the selected new_data\n",
    "imdb_df, imdb_accuracy, imdb_conf_matrix = evaluate_model_on_data(imdb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58018d-2549-4e65-8e58-79f066828e18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Accuracy imdb: {imdb_accuracy}\")\n",
    "#print(imdb_df.head())  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8538fa-9a32-4f5b-8730-885494cfc249",
   "metadata": {},
   "source": [
    "### yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491887d2-7dc5-4612-91e0-bb8ef8baac84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yelp_data = download_and_select_samples(dataset_name = \"yelp\", n_samples = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da23b4-b60b-4b2d-9379-73e3d08cf9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yelp_df, yelp_accuracy, yelp_conf_matrix = evaluate_model_on_data(yelp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905aaddf-3ff6-44ab-be0e-1c59869da50f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yelp_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab1813-4ca9-44de-aa1d-c13507501eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yelp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcdad9e-2681-419f-9d1e-836070d2821b",
   "metadata": {},
   "source": [
    "### amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929ef6c-f245-4048-aa02-1c2ded483581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amazon_data = download_and_select_samples(dataset_name = \"amazon\", n_samples = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a6ec88-c062-4e30-9e44-c482c525a951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amazon_df, amazon_accuracy, amazon_conf_matrix = evaluate_model_on_data(amazon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec053b7b-152e-49e7-984e-c9144de77112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amazon_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7dfe6-6db1-4914-a83b-e7db3beb7bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amazon_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
